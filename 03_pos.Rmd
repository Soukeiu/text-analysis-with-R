# POS tagging

As an initial review of parts of speech, I suggest you watch the following Schoolhouse Rocks videos:

- [A noun is a person, place, or thing.](https://youtu.be/h0m89e9oZko)
- [Interjections](https://youtu.be/YkAX7Vk3JEw)
- [Pronouns](https://youtu.be/Eu1ciVFbecw)
- [Verbs](https://youtu.be/US8mGU1MzYw)
- [Unpack your adjectives](https://youtu.be/NkuuZEey_bs)
- [Lolly Lolly Lolly Get Your Adverbs Here](https://youtu.be/14fXm4FOMPM)
- [Conjunction Junction](https://youtu.be/RPoBE-E8VOc) (personal fave)

Aside from those, you can also learn how bills get passed, about being a victim of gravity, a comparison of the decimal to other numeric systems, and a host of other useful things.

## Basic idea

With <span class="emph">part-of-speech</span> tagging, we classify a word with its corresponding part of speech. The following provides an example.

```{r pos_example, echo=FALSE}
rbind(c('JJ', 'JJ', 'NNS', 'VBP', 'RB'),
      c('Colorless', 'green', 'ideas', 'sleep', 'furiously.')) %>% 
  pander(justify='center')
       

```

We have two adjectives (JJ), a plural noun (NNS), a verb (VBP), and an adverb (RB).

Common analysis may then be used to predict POS given the current state of the text, comparing the grammar of different texts, human-computer interaction, or translation from one language to another.

## Examples

The following approach to POS-tagging is very similar to what we did for sentiment analysis as depicted previously. We have a POS dictionary, and can use an inner join to attach the words to their POS.  Unfortunately this approach is unrealistically simplistic, as additional steps would need to be taken to ensure words are correctly classified.  For example, without more information, we are unable to tell if some words are being used as nouns or verbs (human being vs. being a problematic part of speech).  However, this example can serve as a starting point.

### Barthelme & Carver

In the following we'll compare three texts from Donald Barthelme:

- *The Balloon*
- *The First Thing The Baby Did Wrong*
- *Some Of Us Had Been Threatening Our Friend Colby*

As another comparison, I've included Raymond Carver's *What we talk about when we talk about love*, the unedited version.

```{r barthelme_pos}
balloon = barth %>% 
  filter(id=='balloon.txt') %>% 
  mutate(sentence_id = 1:n()) %>% 
  unnest_tokens(word, sentence, drop=F) %>% 
  ungroup 
colby = barth %>% 
  filter(id=='colby.txt') %>% 
  mutate(sentence_id = 1:n()) %>% 
  unnest_tokens(word, sentence, drop=F) %>% 
  ungroup 
barthelme_pos = balloon %>% 
  inner_join(parts_of_speech) %>% 
  count(pos) %>%
  mutate(text='balloon',
         prop=n/sum(n)) %>% 
  rbind(
    colby %>% 
      inner_join(parts_of_speech) %>% 
      count(pos) %>%
      mutate(text='colby',
             prop=n/sum(n)),
    baby %>% 
      inner_join(parts_of_speech) %>% 
      count(pos) %>%
      mutate(text='baby',
             prop=n/sum(n))
  )

```

```{r carver}
carver_pos = 
  data_frame(file = dir('data/texts_raw/carver/', full.names = TRUE)) %>%
  mutate(text = map(file, read_lines)) %>%
  transmute(id = basename(file), text) %>%
  unnest(text) %>% 
  unnest_tokens(word, text, token='words') %>% 
  inner_join(parts_of_speech) %>% 
  count(pos) %>%
  mutate(text='baby',
         prop=n/sum(n))
```

```{r barthelme_pos_vis}
carver_pos %>% 
  group_by(text) %>% 
  plot_ly() %>% 
  add_markers(x=~pos, y=~prop, color=I('gray50'), opacity=.5, size=I(20), name='Carver') %>% 
  add_markers(x=~pos, y=~prop, color=~text, size=I(10), data=barthelme_pos) %>% 
  theme_plotly() %>% 
  layout(xaxis = list(title=F))
```

<br>

It would appear Barthelme is fairly consistent, and also that relative to the Barthelme texts, Carver preferred nouns and pronouns. 

### More taggin

More sophisticated POS tagging would require the context of the sentence structure. Luckily there are tools to help with that here, in particular via the <span class="pack">openNLP</span>.  In addition, it will require a certain language model to be installed (English is only one of many). I don't recommend doing so unless you are really interested in this (the <span class="pack">openNLPmodels.en</span> is fairly large).

This example more or less follows the help file example for `?Maxent_POS_Tag_Annotator`

```{r eval=FALSE, echo=FALSE}
# POS tagging in R with koRpus; requires installation of treeTagger
# activate library
library(koRpus)

# perform POS tagging
text.tagged <- treetag("data/texts_raw/carver/beginners.txt", 
                       treetagger="manual", 
                       lang="en",
                       TT.options=list(path="C:\\TreeTagger", preset="en"))
```
```{r, eval=F}
# install.packages("openNLPmodels.en", repos = "http://datacube.wu.ac.at/", type = "source")

library(NLP)
library(tm)  # make sure to load this prior to openNLP
library(openNLP)
library(openNLPmodels.en)
```


```{r baby_pos, eval=F}
load('data/barthelme_start.RData')

baby_string0 = barth0 %>% 
  filter(id=='baby.txt')

baby_string = unlist(baby_string0$text) %>% 
  paste(collapse=' ') %>% 
  as.String

init_s_w = annotate(baby_string, list(Maxent_Sent_Token_Annotator(),
                                      Maxent_Word_Token_Annotator()))
pos_res = annotate(baby_string, Maxent_POS_Tag_Annotator(), init_s_w)
word_subset = subset(pos_res, type=='word')
tags = sapply(word_subset$features , '[[', "POS")

baby_pos = data_frame(word=baby_string[word_subset], pos=tags) %>% 
  filter(!str_detect(pos, pattern='[[:punct:]]'))
```

```{r other_pos, eval=FALSE, echo=FALSE}
colby_string0 = barth0 %>% 
  filter(id=='colby.txt')

colby_string = unlist(colby_string0$text) %>% 
  paste(collapse=' ') %>% 
  as.String

init_s_w = annotate(colby_string, list(Maxent_Sent_Token_Annotator(),
                                      Maxent_Word_Token_Annotator()))
pos_res = annotate(colby_string, Maxent_POS_Tag_Annotator(), init_s_w)
word_subset = subset(pos_res, type=='word')
tags = sapply(word_subset$features , '[[', "POS")

colby_pos = data_frame(word=colby_string[word_subset], pos=tags) %>% 
  filter(!str_detect(pos, pattern='[[:punct:]]')) %>% 
  mutate(text='colby')


balloon_string0 = barth0 %>% 
  filter(id=='balloon.txt')

balloon_string = unlist(balloon_string0$text) %>% 
  paste(collapse=' ') %>% 
  as.String

init_s_w = annotate(balloon_string, list(Maxent_Sent_Token_Annotator(),
                                      Maxent_Word_Token_Annotator()))
pos_res = annotate(balloon_string, Maxent_POS_Tag_Annotator(), init_s_w)
word_subset = subset(pos_res, type=='word')
tags = sapply(word_subset$features , '[[', "POS")

balloon_pos = data_frame(word=balloon_string[word_subset], pos=tags) %>% 
  filter(!str_detect(pos, pattern='[[:punct:]]')) %>% 
  mutate(text='balloon')

barthelme_pos = baby_pos %>% 
  mutate(text='baby') %>% 
  bind_rows(colby_pos, balloon_pos) %>% 
  filter(pos != '``') %>% 
  data.frame  # because pander/dplyr issue
save(barthelme_pos, file='data/POS_results.RData')
```


Let's take a look. I've also done the other Barthelme texts as well for comparison.

```{r examine_baby_pos, echo=F}
load('data/POS_results.RData')
pander(barthelme_pos %>% head(20))
```

As we can see, we have quite a few more POS to deal with here.  They come from the [Penn Treebank](https://en.wikipedia.org/wiki/Treebank). The following table notes what the acronyms stand for. I don't pretend to know all the facets to this.

<img src="img/POS-Tags.png" style="display:block; margin: 0 auto;">

Ploting the differences, we now see a little more distinction between *The Balloon* and the other two texts. It is more likely to use the determiners, adjectives, singular nouns, and less likely to use personal pronouns and base verbs and verbs in past tense.

```{r barth_pos, eval=T, echo=F, cache=FALSE}
load('data/POS_results.RData')
balloon_subset = barthelme_pos %>% 
  group_by(text) %>% 
  count(pos) %>%
  mutate(prop = n/sum(n)) %>% 
  filter(text=='balloon', pos %in% c('DT', 'JJ', 'NN', 'PRP', 'VB', 'VBD'))
barthelme_pos %>%
  group_by(text) %>%
  count(pos) %>%
  mutate(prop = n/sum(n)) %>%
  plot_ly(width=800) %>%
  add_markers(x=~pos, y=~prop, color=~text) %>%
  add_markers(x=~pos, y=~prop, color=~text, size=I(15),
              opacity=.5, data=balloon_subset, showlegend=F) %>%
  theme_plotly() %>%
  layout(xaxis = list(showgrid=T, 
                      gridcolor='#0000000D', 
                      title=F))
```


For more information, consult the following:

- [Penn Treebank](http://repository.upenn.edu/cgi/viewcontent.cgi?article=1603&context=cis_reports) 
- [Maxent function](http://maxent.sourceforge.net/about.html) Note that this 'maximum entropy' approach is just one way to go about things. Other models include hidden markov models, conditional random fields, and more recently, deep learning techniques.



For more natural language processing tools in R, consult the corresponding [task view](https://www.r-pkg.org/ctv/NaturalLanguageProcessing).  Much natural language processing is done with deep learning techniques, which generally requires a lot of data, notable computing resources, fine tunining, and often involves optimization towards a specific task.  Most of the cutting edge work there is done in Python, but as a starting point for more common approaches, you can check out the [Natural Language Toolkit](http://www.nltk.org/book/).